model_type="bigru"
attention="luong-dot"
enc_layer=1
enc_emb_dim=20
enc_hid_dim=72
dec_layer=1
dec_emb_dim=20
dec_hid_dim=72
batch_size=100
dropout=0.2
learning_rate=0.005
share_encoder=""
share_decoder=""