model_type="bigru"
attention="luong-dot"
enc_layer=4
enc_emb_dim=24
enc_hid_dim=72
dec_layer=4
dec_emb_dim=24
dec_hid_dim=72
batch_size=10
dropout=0.2
learning_rate=0.001
share_encoder=""
share_decoder=""