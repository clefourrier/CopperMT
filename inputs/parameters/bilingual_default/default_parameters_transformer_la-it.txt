model_type="transformer"
# Encoder
enc_layer=2
enc_emb_dim=24
enc_hid_dim=72
enc_heads=3
# Decoder
dec_layer=2
dec_emb_dim=24
dec_hid_dim=72
dec_heads=3
# Learning
batch_size=65
dropout=0.2
learning_rate=0.005
share_encoder=""
share_decoder=""