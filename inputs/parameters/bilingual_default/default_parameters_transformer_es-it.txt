model_type="transformer"
# Encoder
enc_layer=1
enc_emb_dim=24
enc_hid_dim=54
enc_heads=1
# Decoder
dec_layer=1
dec_emb_dim=24
dec_hid_dim=54
dec_heads=1
# Learning
batch_size=65
dropout=0.2
learning_rate=0.005
share_encoder=""
share_decoder=""