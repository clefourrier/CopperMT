model_type="bigru"
attention="luong-dot"
enc_layer=2
enc_emb_dim=20
enc_hid_dim=72
dec_layer=2
dec_emb_dim=20
dec_hid_dim=72
batch_size=10
dropout=0.2
learning_rate=0.001
share_encoder=""
share_decoder=""